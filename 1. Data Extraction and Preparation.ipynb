{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d0f304",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "premier-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from utils import * # utils.py contains all etl functions needed for data preparation\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeca1ff",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06db608",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# data file locations\n",
    "FILE_PATH = '0_raw_data/'\n",
    "FILE_EXTENSION = '.csv'\n",
    "INPUT_DATA_DIR = '1_input/input.csv'\n",
    "STARTING_TABLES  = \\\n",
    "['pt_icu_outcome', 'vitals_hourly', 'labs_hourly', \n",
    " 'gcs_hourly', 'admissions', 'patients']\n",
    "FILE_DIR = [FILE_PATH + name + FILE_EXTENSION for name in STARTING_TABLES]\n",
    "\n",
    "# data ingestion\n",
    "raw_icu = pd.read_csv(FILE_DIR[0])\n",
    "raw_vitals = pd.read_csv(FILE_DIR[1])\n",
    "raw_labs = pd.read_csv(FILE_DIR[2])\n",
    "raw_gcs = pd.read_csv(FILE_DIR[3]) #Glasgow Coma Score\n",
    "raw_ad = pd.read_csv(FILE_DIR[4])\n",
    "raw_patients = pd.read_csv(FILE_DIR[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b698aa",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc0da62",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "# pt_icu_outcome ETL\n",
    "pt_icu = pt_icu_etl(raw_icu)\n",
    "pt_icu_cleaned = pd.get_dummies(pt_icu, \n",
    "                                columns=['age_bins','intime_weekday']) # --for ML model\n",
    "# patients ETL (gender feature keep 'M')\n",
    "patients_cleaned = pd.get_dummies(raw_patients.loc[:,('subject_id','gender')],\n",
    "                                  drop_first=True,).set_index('subject_id') #--for ML model\n",
    "# admission ETL\n",
    "admission = admission_etl_function(raw_ad)\n",
    "# --for ML model\n",
    "adm_dummies = pd.get_dummies(admission, drop_first=True,\n",
    "                             columns = ['re_adm_in30d','english_speaker'])\n",
    "adm_dummies = pd.get_dummies(adm_dummies, \n",
    "                             columns = ['insurance','admission_type'],\n",
    "                             prefix=['insure','adm_type'])\n",
    "cols_to_keep_admission = ('hadm_id','len_of_adm','re_adm_in30d_True',\n",
    "                          'english_speaker_True', 'insure_government','insure_medicaid',\n",
    "                          'insure_medicare','insure_private','insure_selfpay',\n",
    "                          'adm_type_elective','adm_type_emergency','adm_type_urgent')\n",
    "admission_cleaned = adm_dummies.reset_index().loc[:, cols_to_keep_admission]\n",
    "\n",
    "# vitals, labs and gcs hourly tables ETL\n",
    "first_24_vital_agg = hourly_vitals_etl(raw_vitals)\n",
    "first_24_labs_agg = hourly_labs_etl(raw_labs)\n",
    "first_24_gcs_agg = hourly_gcs_etl(raw_gcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "forty-yield",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# merge pt_icu_outcome with admission, vitals, GCSs and labs tables\n",
    "# for Research Question 1\n",
    "icu_n_patients = pd.merge(pt_icu_cleaned, \n",
    "                           patients_cleaned, \n",
    "                           how='inner', on='subject_id', suffixes=('','_pt'))\n",
    "icu_n_admission = pd.merge(icu_n_patients, \n",
    "                           admission_cleaned, \n",
    "                           how='inner', on='hadm_id', suffixes=('','_adm'))\n",
    "icu_n_vital = pd.merge(icu_n_admission, \n",
    "                       first_24_vital_agg, \n",
    "                       how='inner', on='icustay_id', suffixes=('','_vt'))\n",
    "icu_n_gcs = pd.merge(icu_n_vital, \n",
    "                     first_24_gcs_agg, \n",
    "                     how='inner', on='icustay_id', suffixes=('','_gcs'))\n",
    "icu_n_labs = pd.merge(icu_n_gcs, \n",
    "                      first_24_labs_agg, \n",
    "                      how='inner', on='icustay_id', suffixes=('','_labs'))\n",
    "\n",
    "# data for research question 2\n",
    "rq2_dataset = pd.merge(pt_icu,\n",
    "                       admission,\n",
    "                       how='inner', on='hadm_id', suffixes=('','_hadm'))\n",
    "\n",
    "# data for visualisation\n",
    "pre_OHE_merge0 = pd.merge(pt_icu,\n",
    "                          raw_patients,\n",
    "                          how='inner', on='subject_id', suffixes=('','_pt'))\n",
    "pre_OHE_merge1 = pd.merge(pre_OHE_merge0, \n",
    "                          admission, \n",
    "                          how='inner', on='hadm_id', suffixes=('','_adm'))\n",
    "pre_OHE_merge2 = pd.merge(pre_OHE_merge1,\n",
    "                          first_24_vital_agg, \n",
    "                          how='inner', on='icustay_id', suffixes=('','_vital'))\n",
    "pre_OHE_merge3 = pd.merge(pre_OHE_merge2, \n",
    "                          first_24_gcs_agg, \n",
    "                          how='inner', on='icustay_id', suffixes=('','_gcs'))\n",
    "pre_OHE_merge4 = pd.merge(pre_OHE_merge3, \n",
    "                          first_24_labs_agg, \n",
    "                          how='inner', on='icustay_id', suffixes=('','_labs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1abfd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'subject_id', 'dob', 'hadm_id', 'admittime', 'dischtime',\n",
       "       'icustay_id', 'age_years', 'intime', 'outtime', 'los', 'hosp_deathtime',\n",
       "       'icu_expire_flag', 'hospital_expire_flag', 'dod', 'expire_flag',\n",
       "       'ttd_days', 'age_bins', 'intime_weekday', 'icu_adm_weekend', 'ttd_bins',\n",
       "       'standard_mortality_label', 'row_id_hadm', 'admittime_hadm',\n",
       "       'dischtime_hadm', 'deathtime', 'admission_type', 'admission_location',\n",
       "       'discharge_location', 'insurance', 'language', 'religion',\n",
       "       'marital_status', 'ethnicity', 'edregtime', 'edouttime', 'diagnosis',\n",
       "       'hospital_expire_flag_hadm', 'has_chartevents_data', 'prev_dischtime',\n",
       "       'tt_next_adm_days', 're_adm_in30d', 'len_of_adm', 'english_speaker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rq2_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61cc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns \n",
    "# - drop columns with only 1 unique value\n",
    "col_w_1_value = list((icu_n_labs.nunique())[icu_n_labs.nunique()<2].index)\n",
    "icu_n_labs_0 = icu_n_labs.drop(col_w_1_value, axis=1)\n",
    "# - drop columns that are not needed for ML model development\n",
    "cols_to_drop_rq1 = \\\n",
    "['row_id', 'subject_id', 'dob', 'hadm_id', 'admittime', 'dischtime',\n",
    " 'icustay_id', 'age_years', 'intime', 'outtime', 'hosp_deathtime',\n",
    " 'icu_expire_flag', 'hospital_expire_flag', 'dod', 'expire_flag',\n",
    " 'ttd_days', 'icu_adm_weekend', 'ttd_bins', ] # columns not needed\n",
    "# - keep columns needed for research question 2\n",
    "cols_to_keep_rq2 = \\\n",
    "['subject_id', 'hadm_id', 'icustay_id', 'age_years','age_bins', 'icu_adm_weekend',\n",
    " 'standard_mortality_label', 'los', 're_adm_in30d',\n",
    " 'insurance', 'admission_type',] # columns needed\n",
    "# - drop columns that are not needed for data visualisation\n",
    "cols_to_drop_viz = \\\n",
    "['row_id_pt', 'dob_pt', 'dod_pt', 'expire_flag_pt', \n",
    " 'row_id_adm', 'admittime_adm', 'dischtime_adm','hospital_expire_flag_adm',] # columns not needed\n",
    "\n",
    "# save data tables\n",
    "pt_icu_final = icu_n_labs_0.drop(cols_to_drop_rq1, axis=1)\n",
    "pt_icu_final.to_pickle(\"1_input/input_rq1.pkl\") # for research question 1\n",
    "\n",
    "rq2_final = rq2_dataset.loc[:,cols_to_keep_rq2] # csv to be read in R\n",
    "rq2_final.to_csv(\"1_input/input_rq2.csv\") #for research question 2\n",
    "\n",
    "viz_final = pre_OHE_merge4.drop(cols_to_drop_viz, axis=1)\n",
    "viz_final.to_pickle(\"1_input/input_viz.pkl\") #for research question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62539f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final table for research q1 before dropping id provided of size:\t51065 rows and 80 columns\n",
      "\n",
      "List of columns in the dataset:\n",
      "['row_id', 'subject_id', 'dob', 'hadm_id', 'admittime', 'dischtime', 'icustay_id', 'age_years', 'intime', 'outtime', 'los', 'hosp_deathtime', 'icu_expire_flag', 'hospital_expire_flag', 'dod', 'expire_flag', 'ttd_days', 'icu_adm_weekend', 'ttd_bins', 'standard_mortality_label', 'age_bins_under44', 'age_bins_45-54', 'age_bins_55-64', 'age_bins_65-74', 'age_bins_over75', 'intime_weekday_Friday', 'intime_weekday_Monday', 'intime_weekday_Saturday', 'intime_weekday_Sunday', 'intime_weekday_Thursday', 'intime_weekday_Tuesday', 'intime_weekday_Wednesday', 'gender_M', 'len_of_adm', 're_adm_in30d_True', 'english_speaker_True', 'insure_government', 'insure_medicaid', 'insure_medicare', 'insure_private', 'insure_selfpay', 'adm_type_elective', 'adm_type_emergency', 'adm_type_urgent', 'bp_elevated', 'bp_hbp_s1', 'bp_hbp_s2', 'bp_hyptsn_crisis', 'abnorm_spo2', 'fever', 'tachycardia', 'bradycardia', 'diabetes', 'abnorm_map', 'endotrachflag', 'eye_no_resp', 'motor_no_resp', 'verbal_no_resp', 'gcs_severe', 'gcs_moderate', 'abnorm_albumin', 'abnorm_bilirubin', 'abnorm_alt', 'abnorm_ast', 'abnorm_hemoglobin', 'abnorm_hematocrit', 'abnorm_wbc', 'abnorm_platelets', 'abnorm_sodium', 'abnorm_chloride', 'abnorm_bicarbonate', 'abnorm_troponin', 'abnorm_bloodureanitrogen', 'abnorm_partialpressureo2', 'abnorm_creatinine', 'abnorm_glucose', 'abnorm_neutrophil', 'abnorm_creactiveprotein', 'abnorm_lactate', 'abnorm_inr']\n",
      "over 50% values missing in following columns:\n",
      "hosp_deathtime   0.9578\n",
      "ttd_bins         0.5538\n",
      "ttd_days         0.5538\n",
      "dod              0.5538\n",
      "dtype: float64\n",
      "Column row_id has 51065 unique values\n",
      "Column subject_id has 37530 unique values\n",
      "Column hadm_id has 47820 unique values\n",
      "Column icustay_id has 51065 unique values\n",
      "Column intime_weekday_Friday has 2 unique values\n",
      "Column insure_medicaid has 2 unique values\n",
      "Column abnorm_chloride has 2 unique values\n"
     ]
    }
   ],
   "source": [
    "dataset_brief(icu_n_labs_0,'final table for research q1 before dropping id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "710bfafe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    47368\n",
       "True      3697\n",
       "Name: standard_mortality_label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icu_n_labs_0.standard_mortality_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69047e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final table for research q2 before dropping id provided of size:\t61516 rows and 11 columns\n",
      "\n",
      "List of columns in the dataset:\n",
      "['subject_id', 'hadm_id', 'icustay_id', 'age_years', 'age_bins', 'icu_adm_weekend', 'standard_mortality_label', 'los', 're_adm_in30d', 'insurance', 'admission_type']\n",
      "over 50% values missing in following columns:\n",
      "Series([], dtype: float64)\n",
      "Column subject_id has 46464 unique values\n",
      "Column hadm_id has 57771 unique values\n",
      "Column icustay_id has 61516 unique values\n"
     ]
    }
   ],
   "source": [
    "dataset_brief(rq2_final,'final table for research q2 before dropping id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
